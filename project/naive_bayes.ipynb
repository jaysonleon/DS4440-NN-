{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install numpy \n",
    "# %pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
    "# %pip install pandas  \n",
    "# %pip install huggingFace\n",
    "# %pip install transformers\n",
    "# %pip install nltk\n",
    "# %pip install scikit-learn\n",
    "# %pip install datasets\n",
    "# %pip install pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1000)>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1000)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# Numpy \n",
    "import numpy as np\n",
    "# Pickle\n",
    "import pickle\n",
    "# Pandas\n",
    "import pandas as pd\n",
    "# Hugging Face\n",
    "import huggingface_hub\n",
    "from datasets import load_dataset\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "# PyTorch\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# SkLearn\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# NLTK\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "# nltk.download()\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets \n",
    "# Hate Xplain\n",
    "hate_xplain = pd.read_csv(\"data/hate_xplain.csv\")\n",
    "\n",
    "# Implicit Hate \n",
    "implicit_hate = pd.read_csv('data/implicit-hate-corpus/implicit_hate_v1_stg2_posts.tsv', delimiter='\\t')\n",
    "label_map = {\n",
    "    'white_grievance': 0, 'incitement': 1, 'inferiority': 2,\n",
    "    'irony': 3, 'stereotypical': 4, 'threatening': 5, 'other': 6\n",
    "}\n",
    "\n",
    "implicit_hate['class_label'] = implicit_hate['implicit_class'].map(label_map)\n",
    "implicit_hate.drop(\"extra_implicit_class\", axis=1, inplace=True)\n",
    "\n",
    "# Toxic-Spans\n",
    "annotations = pd.read_csv('data/toxic-spans/annotations.csv')\n",
    "comments = pd.read_csv('data/toxic-spans/comments.csv')\n",
    "\n",
    "toxic_spans = pd.merge(annotations, comments, on='comment_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>25291</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>25292</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>25294</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>25295</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>25296</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0               0      3            0                   0        3      2   \n",
       "1               1      3            0                   3        0      1   \n",
       "2               2      3            0                   3        0      1   \n",
       "3               3      3            0                   2        1      1   \n",
       "4               4      6            0                   6        0      1   \n",
       "...           ...    ...          ...                 ...      ...    ...   \n",
       "24778       25291      3            0                   2        1      1   \n",
       "24779       25292      3            0                   1        2      2   \n",
       "24780       25294      3            0                   3        0      1   \n",
       "24781       25295      6            0                   6        0      1   \n",
       "24782       25296      3            0                   0        3      2   \n",
       "\n",
       "                                                   tweet  \n",
       "0      !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n",
       "...                                                  ...  \n",
       "24778  you's a muthaf***in lie &#8220;@LifeAsKing: @2...  \n",
       "24779  you've gone and broke the wrong heart baby, an...  \n",
       "24780  young buck wanna eat!!.. dat nigguh like I ain...  \n",
       "24781              youu got wild bitches tellin you lies  \n",
       "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...  \n",
       "\n",
       "[24783 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hate_xplain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>implicit_class</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\" : jewish harvard professor noel ignatiev w...</td>\n",
       "      <td>white_grievance</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt : tune in today's jmt for my interview w /...</td>\n",
       "      <td>irony</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>: : hate posters ? you want hate buddy ? read ...</td>\n",
       "      <td>white_grievance</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>: hunt for white women : black racist serial k...</td>\n",
       "      <td>stereotypical</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>: looks like he was a fan of the islamic jew-h...</td>\n",
       "      <td>stereotypical</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6341</th>\n",
       "      <td>Seeing prostitutes is morally wrong, but being...</td>\n",
       "      <td>irony</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6342</th>\n",
       "      <td>I wonder how many females I raped today I spen...</td>\n",
       "      <td>irony</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6343</th>\n",
       "      <td>Having a criminal record is more attractive to...</td>\n",
       "      <td>stereotypical</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6344</th>\n",
       "      <td>Another advantage of being a female: getting b...</td>\n",
       "      <td>inferiority</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6345</th>\n",
       "      <td>If men are so privileged and women have it so ...</td>\n",
       "      <td>irony</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6346 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   post   implicit_class  \\\n",
       "0       \" : jewish harvard professor noel ignatiev w...  white_grievance   \n",
       "1      rt : tune in today's jmt for my interview w /...            irony   \n",
       "2     : : hate posters ? you want hate buddy ? read ...  white_grievance   \n",
       "3     : hunt for white women : black racist serial k...    stereotypical   \n",
       "4     : looks like he was a fan of the islamic jew-h...    stereotypical   \n",
       "...                                                 ...              ...   \n",
       "6341  Seeing prostitutes is morally wrong, but being...            irony   \n",
       "6342  I wonder how many females I raped today I spen...            irony   \n",
       "6343  Having a criminal record is more attractive to...    stereotypical   \n",
       "6344  Another advantage of being a female: getting b...      inferiority   \n",
       "6345  If men are so privileged and women have it so ...            irony   \n",
       "\n",
       "      class_label  \n",
       "0               0  \n",
       "1               3  \n",
       "2               0  \n",
       "3               4  \n",
       "4               4  \n",
       "...           ...  \n",
       "6341            3  \n",
       "6342            3  \n",
       "6343            4  \n",
       "6344            2  \n",
       "6345            3  \n",
       "\n",
       "[6346 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implicit_hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>worker</th>\n",
       "      <th>country</th>\n",
       "      <th>all toxic</th>\n",
       "      <th>not toxic</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5167187</td>\n",
       "      <td>868</td>\n",
       "      <td>USA</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>That's right. They are not normal. And I am st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5167187</td>\n",
       "      <td>1316</td>\n",
       "      <td>USA</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>That's right. They are not normal. And I am st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5167187</td>\n",
       "      <td>1295</td>\n",
       "      <td>USA</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>That's right. They are not normal. And I am st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5167187</td>\n",
       "      <td>2856</td>\n",
       "      <td>USA</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>That's right. They are not normal. And I am st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5521110</td>\n",
       "      <td>2076</td>\n",
       "      <td>USA</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>yep, this crap sounds like its from a libertarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59187</th>\n",
       "      <td>59736</td>\n",
       "      <td>6209917</td>\n",
       "      <td>1491</td>\n",
       "      <td>USA</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Quite the contrary...because I carry every day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59193</th>\n",
       "      <td>59742</td>\n",
       "      <td>6209917</td>\n",
       "      <td>1761</td>\n",
       "      <td>USA</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Quite the contrary...because I carry every day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59200</th>\n",
       "      <td>59749</td>\n",
       "      <td>6209917</td>\n",
       "      <td>74</td>\n",
       "      <td>USA</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Quite the contrary...because I carry every day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59203</th>\n",
       "      <td>59752</td>\n",
       "      <td>6209917</td>\n",
       "      <td>3147</td>\n",
       "      <td>USA</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Quite the contrary...because I carry every day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59213</th>\n",
       "      <td>59762</td>\n",
       "      <td>6209917</td>\n",
       "      <td>2084</td>\n",
       "      <td>USA</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Quite the contrary...because I carry every day...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23617 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       annotation  comment_id  worker country  all toxic  not toxic  \\\n",
       "0               0     5167187     868     USA      False      False   \n",
       "1               1     5167187    1316     USA      False      False   \n",
       "2               2     5167187    1295     USA      False       True   \n",
       "3               3     5167187    2856     USA      False      False   \n",
       "5               5     5521110    2076     USA      False      False   \n",
       "...           ...         ...     ...     ...        ...        ...   \n",
       "59187       59736     6209917    1491     USA      False      False   \n",
       "59193       59742     6209917    1761     USA       True       True   \n",
       "59200       59749     6209917      74     USA       True       True   \n",
       "59203       59752     6209917    3147     USA       True       True   \n",
       "59213       59762     6209917    2084     USA      False      False   \n",
       "\n",
       "                                            comment_text  \n",
       "0      That's right. They are not normal. And I am st...  \n",
       "1      That's right. They are not normal. And I am st...  \n",
       "2      That's right. They are not normal. And I am st...  \n",
       "3      That's right. They are not normal. And I am st...  \n",
       "5      yep, this crap sounds like its from a libertarian  \n",
       "...                                                  ...  \n",
       "59187  Quite the contrary...because I carry every day...  \n",
       "59193  Quite the contrary...because I carry every day...  \n",
       "59200  Quite the contrary...because I carry every day...  \n",
       "59203  Quite the contrary...because I carry every day...  \n",
       "59213  Quite the contrary...because I carry every day...  \n",
       "\n",
       "[23617 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_annotations = toxic_spans[toxic_spans['country'] == 'USA']\n",
    "english_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_preprocess_text(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    porter = PorterStemmer()\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [porter.stem(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def bow_preprocess_data(data, label, vectorizer): \n",
    "    data = data.apply(bow_preprocess_text)\n",
    "    X = vectorizer.fit_transform(data)\n",
    "    y = label\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "# Hate Xplain\n",
    "hx_X, hx_y = bow_preprocess_data(hate_xplain['tweet'], hate_xplain['class'], vectorizer)\n",
    "hx_train_X, hx_test_X, hx_train_y, hx_test_y = train_test_split(hx_X, hx_y, test_size=0.2, random_state=42)\n",
    "hx_n_classes = len(np.unique(hate_xplain['class']))\n",
    "\n",
    "# Implicit Hate\n",
    "ih_X, ih_y = bow_preprocess_data(implicit_hate['post'], implicit_hate['class_label'], vectorizer)\n",
    "ih_train_X, ih_test_X, ih_train_y, ih_test_y = train_test_split(ih_X, ih_y, test_size=0.2, random_state=42)\n",
    "ix_n_classes = len(np.unique(implicit_hate['class_label']))\n",
    "\n",
    "# Toxic-Spans\n",
    "ts_X, ts_y = bow_preprocess_data(toxic_spans['comment_text'], toxic_spans['all toxic'], vectorizer)\n",
    "ts_train_X, ts_test_X, ts_train_y, ts_test_y = train_test_split(ts_X, ts_y, test_size=0.2, random_state=42)\n",
    "ts_n_classes = len(np.unique(toxic_spans['all toxic']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_test, y_pred):\n",
    "    classification = classification_report(y_test, y_pred, zero_division=1)\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(train_X, train_y, test_X, test_y, savepath: str): \n",
    "    model = MultinomialNB()\n",
    "    model.fit(train_X, train_y)\n",
    "    pickle.dump(model, open(savepath, 'wb'))\n",
    "    y_pred = model.predict(test_X)\n",
    "    stats = evaluate(test_y, y_pred)\n",
    "    return stats \n",
    "\n",
    "def print_stats(stats, name: str):\n",
    "    print(f\"Stats for {name}\")\n",
    "    print(stats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for Hate Xplain\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.09      0.14       290\n",
      "           1       0.88      0.97      0.92      3832\n",
      "           2       0.83      0.65      0.73       835\n",
      "\n",
      "    accuracy                           0.86      4957\n",
      "   macro avg       0.68      0.57      0.60      4957\n",
      "weighted avg       0.84      0.86      0.84      4957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hx_stats = run(hx_train_X, hx_train_y, hx_test_X, hx_test_y, savepath='NB/hate_explain_NB.pkl')\n",
    "print_stats(hx_stats, \"Hate Xplain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for Implicit Hate\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.71      0.59       325\n",
      "           1       0.54      0.49      0.51       253\n",
      "           2       0.63      0.37      0.47       167\n",
      "           3       0.57      0.40      0.47       169\n",
      "           4       0.49      0.47      0.48       219\n",
      "           5       0.49      0.62      0.55       120\n",
      "           6       1.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.52      1270\n",
      "   macro avg       0.60      0.44      0.44      1270\n",
      "weighted avg       0.54      0.52      0.51      1270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ih_stats = run(ih_train_X, ih_train_y, ih_test_X, ih_test_y, savepath='NB/implicit_hate_NB.pkl')\n",
    "print_stats(ih_stats, \"Implicit Hate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for Toxic-Spans\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.66      0.80      0.73      7491\n",
      "        True       0.47      0.30      0.36      4352\n",
      "\n",
      "    accuracy                           0.62     11843\n",
      "   macro avg       0.56      0.55      0.54     11843\n",
      "weighted avg       0.59      0.62      0.59     11843\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ts_stats = run(ts_train_X, ts_train_y, ts_test_X, ts_test_y, savepath='NB/toxic_spans_NB.pkl')\n",
    "print_stats(ts_stats, \"Toxic-Spans\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
