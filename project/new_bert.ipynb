{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas\n",
    "import pandas as pd\n",
    "# Hugging Face\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "# PyTorch\n",
    "import torch \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "# SkLearn\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nnsight import NNsight\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>25291</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>25292</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>25294</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>25295</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>25296</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0               0      3            0                   0        3      2   \n",
       "1               1      3            0                   3        0      1   \n",
       "2               2      3            0                   3        0      1   \n",
       "3               3      3            0                   2        1      1   \n",
       "4               4      6            0                   6        0      1   \n",
       "...           ...    ...          ...                 ...      ...    ...   \n",
       "24778       25291      3            0                   2        1      1   \n",
       "24779       25292      3            0                   1        2      2   \n",
       "24780       25294      3            0                   3        0      1   \n",
       "24781       25295      6            0                   6        0      1   \n",
       "24782       25296      3            0                   0        3      2   \n",
       "\n",
       "                                                   tweet  \n",
       "0      !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n",
       "...                                                  ...  \n",
       "24778  you's a muthaf***in lie &#8220;@LifeAsKing: @2...  \n",
       "24779  you've gone and broke the wrong heart baby, an...  \n",
       "24780  young buck wanna eat!!.. dat nigguh like I ain...  \n",
       "24781              youu got wild bitches tellin you lies  \n",
       "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...  \n",
       "\n",
       "[24783 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Datasets \n",
    "# Hate Xplain\n",
    "hate_xplain = pd.read_csv(r'data\\hate_xplain.csv')\n",
    "\n",
    "# Implicit Hate \n",
    "implicit_hate = pd.read_csv(r'data\\implicit_hate_v1_stg2_posts.tsv', delimiter='\\t')\n",
    "label_map = {\n",
    "    'white_grievance': 0, 'incitement': 1, 'inferiority': 2,\n",
    "    'irony': 3, 'stereotypical': 4, 'threatening': 5, 'other': 6\n",
    "}\n",
    "implicit_hate['class_label'] = implicit_hate['implicit_class'].map(label_map)\n",
    "implicit_hate.drop(\"extra_implicit_class\", axis=1, inplace=True)\n",
    "\n",
    "# hate_xplain = hate_xplain.sample(n=1000, random_state=42)\n",
    "hate_xplain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(texts, labels, tokenizer, max_length):\n",
    "    if isinstance(texts, pd.Series):\n",
    "        texts = texts.tolist()\n",
    "    texts = [str(text) for text in texts] \n",
    "\n",
    "    if isinstance(labels, pd.Series):\n",
    "        labels = labels.tolist()\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    encodings = tokenizer(texts, truncation=True, padding='max_length', max_length=max_length, return_tensors=\"pt\")\n",
    "    dataset = torch.utils.data.TensorDataset(encodings[\"input_ids\"], encodings[\"attention_mask\"], labels)\n",
    "    return dataset\n",
    "\n",
    "def train(model, data_loader, optimizer, epochs, device=None):\n",
    "    device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for input_ids, attention_mask, labels in data_loader:\n",
    "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch {epoch+1} Loss: {loss.item()}\")\n",
    "\n",
    "def evaluate(model, data_loader, device=None):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids, attention_mask, labels = tuple(t.to(device) for t in batch)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return all_preds, all_labels\n",
    "\n",
    "def freeze_bert_layers(model, layers: list):\n",
    "    for name, param in model.named_parameters():\n",
    "        # only unfreeze the layers in the list\n",
    "        for layer in layers:\n",
    "            if layer in name:\n",
    "                param.requires_grad = True\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bert = 'bert-base-uncased'\n",
    "new_bert = AutoModelForSequenceClassification.from_pretrained(bert, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bert = freeze_bert_layers(new_bert, ['encoder.layer.11'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1240, 310)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hx_train_text, hx_test_text, hx_train_labels, hx_test_labels = train_test_split(hate_xplain['tweet'], hate_xplain['class'], test_size=0.2)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(bert, clean_up_tokenization_spaces=True)\n",
    "hx_train = tokenize_data(hx_train_text, hx_train_labels, tokenizer, 512)\n",
    "hx_test = tokenize_data(hx_test_text, hx_test_labels, tokenizer, 512)\n",
    "\n",
    "hx_train_loader = DataLoader(hx_train, batch_size=16, shuffle=True)\n",
    "hx_test_loader = DataLoader(hx_test, batch_size=16, shuffle=True)\n",
    "\n",
    "hx_train_loader.__len__(), hx_test_loader.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.05439606308937073\n",
      "Epoch 2 Loss: 0.05981718748807907\n",
      "Epoch 3 Loss: 0.08305776119232178\n",
      "Epoch 4 Loss: 0.12415436655282974\n",
      "Epoch 5 Loss: 0.07273364812135696\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.AdamW(new_bert.parameters(), lr=5e-5)\n",
    "train(new_bert, hx_train_loader, optimizer, 5, 'cuda')\n",
    "new_bert.save_pretrained(\"BERT/bert_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bert = AutoModelForSequenceClassification.from_pretrained(\"BERT/bert_full\", num_labels=3)\n",
    "optimizer = optim.AdamW(new_bert.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline HateXplain Accuracy: 0.9231389953600968\n"
     ]
    }
   ],
   "source": [
    "# Baseline HateXplain Accuracy\n",
    "hx_preds, hx_labels = evaluate(new_bert, hx_test_loader, 'cuda')\n",
    "hx_report = accuracy_score(hx_labels, hx_preds)\n",
    "print(f'Baseline HateXplain Accuracy: {hx_report}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_zero_head(model, data_loader, head:int, device=None): \n",
    "    \"\"\"\n",
    "    Evaluate the model and zero out the given head. \n",
    "    Return the predictions and labels.\n",
    "    Args:\n",
    "        model: The NNsight model to evaluate\n",
    "        data_loader: the test set data loader \n",
    "        head: The head # to zero out\n",
    "        device: The device to evaluate on (gpu or cpu)\n",
    "    Returns:\n",
    "        preds: The model's predictions\n",
    "        labels: The model's labels\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    # Batch -> (input_ids, attention_mask, labels)\n",
    "    for batch in data_loader:\n",
    "        outputs, labels = [], []\n",
    "        labels.append(batch[2])\n",
    "        # Begin intervention \n",
    "        with model.trace(batch[0]) as tracer: \n",
    "            # Here, the given head # is zeroed out \n",
    "            model.bert.encoder.layer[head].output = 0.0\n",
    "            output = model.output[0].save()\n",
    "            outputs.append(output)\n",
    "        # End intervention\n",
    "        labels = labels[0]\n",
    "        outputs = outputs[0]\n",
    "        preds = outputs.argmax(dim=1)\n",
    "    return preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nnsight\\envoy.py:104: UserWarning: Module of type `<class 'transformers.models.bert.modeling_bert.BertAttention'>` has pre-defined a `output` attribute. nnsight access for `output` will be mounted at `.nns_output` instead of `.output` for this module only.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nnsight\\envoy.py:104: UserWarning: Module of type `<class 'transformers.models.bert.modeling_bert.BertLayer'>` has pre-defined a `output` attribute. nnsight access for `output` will be mounted at `.nns_output` instead of `.output` for this module only.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "nn_model = NNsight(new_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeroing out attention head 0.\n",
      "  - Accuracy: 0.6923076923076923\n",
      "Zeroing out attention head 1.\n",
      "  - Accuracy: 0.5384615384615384\n",
      "Zeroing out attention head 2.\n",
      "  - Accuracy: 0.5384615384615384\n",
      "Zeroing out attention head 3.\n",
      "  - Accuracy: 0.5384615384615384\n",
      "Zeroing out attention head 4.\n",
      "  - Accuracy: 0.6923076923076923\n",
      "Zeroing out attention head 5.\n",
      "  - Accuracy: 0.6153846153846154\n",
      "Zeroing out attention head 6.\n",
      "  - Accuracy: 0.9230769230769231\n",
      "Zeroing out attention head 7.\n",
      "  - Accuracy: 0.6153846153846154\n",
      "Zeroing out attention head 8.\n",
      "  - Accuracy: 0.6923076923076923\n",
      "Zeroing out attention head 9.\n",
      "  - Accuracy: 0.6923076923076923\n",
      "Zeroing out attention head 10.\n",
      "  - Accuracy: 0.7692307692307693\n",
      "Zeroing out attention head 11.\n",
      "  - Accuracy: 0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "for i in range(12): \n",
    "    print(f\"Zeroing out attention head {i}.\")\n",
    "    preds, labels = evaluate_and_zero_head(nn_model, hx_test_loader, i, 'cuda')\n",
    "\n",
    "    preds, labels = preds.cpu().numpy(), labels.cpu().numpy()\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"  - Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318, 80)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ih_train_text, ih_test_text, ih_train_labels, ih_test_labels = train_test_split(implicit_hate['post'], implicit_hate['class_label'], test_size=0.2)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(bert, clean_up_tokenization_spaces=True)\n",
    "ih_train = tokenize_data(ih_train_text, ih_train_labels, tokenizer, 512)\n",
    "ih_test = tokenize_data(ih_test_text, ih_test_labels, tokenizer, 512)\n",
    "\n",
    "ih_train_loader = DataLoader(ih_train, batch_size=16, shuffle=True)\n",
    "ih_test_loader = DataLoader(ih_test, batch_size=16, shuffle=True)\n",
    "\n",
    "ih_train_loader.__len__(), ih_test_loader.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 1.5557514429092407\n",
      "Epoch 2 Loss: 1.1465587615966797\n",
      "Epoch 3 Loss: 0.9820433855056763\n",
      "Epoch 4 Loss: 1.1998872756958008\n",
      "Epoch 5 Loss: 1.2950735092163086\n",
      "Baseline Implicit Hate Accuracy: 0.6236220472440945\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(bert, num_labels=7)\n",
    "model = freeze_bert_layers(model, ['encoder.layer.11'])\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
    "train(model, ih_train_loader, optimizer, 5, 'cuda')\n",
    "model.save_pretrained(\"BERT/bert_ih_baseline\")\n",
    "preds, labels = evaluate(model, ih_test_loader, 'cuda')\n",
    "ih_report = accuracy_score(labels, preds)\n",
    "print(f'Baseline Implicit Hate Accuracy: {ih_report}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at BERT/bert_full and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('BERT/bert_full', num_labels=7, ignore_mismatched_sizes=True)\n",
    "model = freeze_bert_layers(model, ['encoder.layer.11'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 1.5082802772521973\n",
      "Epoch 2 Loss: 1.8577481508255005\n",
      "Epoch 3 Loss: 0.7282094955444336\n",
      "Epoch 4 Loss: 1.629270315170288\n",
      "Epoch 5 Loss: 1.1496150493621826\n"
     ]
    }
   ],
   "source": [
    "# Transfer learning \n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
    "train(model, ih_train_loader, optimizer, 5, 'cuda')\n",
    "model.save_pretrained(\"BERT/transfer_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transfer learning accuracy: 0.6070866141732284\n"
     ]
    }
   ],
   "source": [
    "preds, labels = evaluate(model, ih_test_loader, 'cuda')\n",
    "report = accuracy_score(labels, preds)\n",
    "print(f\"Transfer learning accuracy: {report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is one head more important - dropping head -> dropping head in overall "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
