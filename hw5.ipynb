{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cbJaXKXGHJqq"
   },
   "source": [
    "## HW5: Implementing Future lens (-ish)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "OOH5hFcaN0az"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OzlQK4rT68Go",
    "outputId": "3f36375c-888c-49cf-fe2d-c66224acde66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: torchvision in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.20.1+cu124)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: filelock in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cQtcaj5VJjFS",
    "outputId": "58c8b980-6498-467f-9b89-03d41556deca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nnsight in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.3.6)\n",
      "Requirement already satisfied: transformers in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nnsight) (4.46.1)\n",
      "Requirement already satisfied: protobuf in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nnsight) (4.25.5)\n",
      "Requirement already satisfied: python-socketio[client] in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nnsight) (5.11.4)\n",
      "Requirement already satisfied: tokenizers>=0.13.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nnsight) (0.20.1)\n",
      "Requirement already satisfied: pydantic>=2.4.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nnsight) (2.9.2)\n",
      "Requirement already satisfied: torch>=2.4.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nnsight) (2.5.1+cu124)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nnsight) (0.2.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nnsight) (0.20.1+cu124)\n",
      "Requirement already satisfied: accelerate in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nnsight) (1.1.0)\n",
      "Requirement already satisfied: diffusers in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nnsight) (0.31.0)\n",
      "Requirement already satisfied: einops in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nnsight) (0.8.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=2.4.0->nnsight) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=2.4.0->nnsight) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=2.4.0->nnsight) (4.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tokenizers>=0.13.0->nnsight) (0.26.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2.4.0->nnsight) (3.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2.4.0->nnsight) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2.4.0->nnsight) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2.4.0->nnsight) (2024.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2.4.0->nnsight) (75.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2.4.0->nnsight) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch>=2.4.0->nnsight) (1.3.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate->nnsight) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\owner\\appdata\\roaming\\python\\python312\\site-packages (from accelerate->nnsight) (24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\owner\\appdata\\roaming\\python\\python312\\site-packages (from accelerate->nnsight) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate->nnsight) (6.0.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate->nnsight) (0.4.5)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from diffusers->nnsight) (8.5.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from diffusers->nnsight) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from diffusers->nnsight) (2.32.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from diffusers->nnsight) (10.4.0)\n",
      "Requirement already satisfied: bidict>=0.21.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-socketio[client]->nnsight) (0.23.1)\n",
      "Requirement already satisfied: python-engineio>=4.8.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-socketio[client]->nnsight) (4.10.1)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-socketio[client]->nnsight) (1.8.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers->nnsight) (4.66.5)\n",
      "Requirement already satisfied: simple-websocket>=0.10.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-engineio>=4.8.0->python-socketio[client]->nnsight) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->diffusers->nnsight) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->diffusers->nnsight) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->diffusers->nnsight) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->diffusers->nnsight) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\owner\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers->nnsight) (0.4.6)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from importlib-metadata->diffusers->nnsight) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=2.4.0->nnsight) (3.0.2)\n",
      "Requirement already satisfied: wsproto in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from simple-websocket>=0.10.0->python-engineio>=4.8.0->python-socketio[client]->nnsight) (1.2.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wsproto->simple-websocket>=0.10.0->python-engineio>=4.8.0->python-socketio[client]->nnsight) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nnsight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "EQaE1ROx90Em"
   },
   "outputs": [],
   "source": [
    "from nnsight import LanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "k6SxoJcGGX0i"
   },
   "outputs": [],
   "source": [
    "HF_TOKEN = \"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\"\n",
    "NDIF_API_KEY = \"77WamZVzi9t1qlqYI5sf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "LqFaxwwfR8AS"
   },
   "outputs": [],
   "source": [
    "from nnsight import CONFIG\n",
    "CONFIG.set_default_api_key(NDIF_API_KEY)\n",
    "os.environ['HF_TOKEN'] = HF_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jYAEWrgZ9vvA",
    "outputId": "dccd9444-51ca-4da4-8096-0980166cffd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8ZE6iqccFNk"
   },
   "source": [
    "### 1. Assemble train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "gcx6N3awcGuH"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "train_csv = \"https://github.com/KoyenaPal/future-lens/raw/main/data/training_data_teacher_11000.csv\"\n",
    "test_csv  = \"https://github.com/KoyenaPal/future-lens/raw/main/data/testing_data_teacher_1000.csv\"\n",
    "\n",
    "train_data = pd.read_csv(train_csv)\n",
    "test_data  = pd.read_csv(test_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0TdHR7S60zPU"
   },
   "source": [
    "`\"decoded_phrase\"` is the observed completion (from the Pile data); `\"teacher_phrase\"` is predicted completion from GPT-J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "uKsxLK1wjqHt",
    "outputId": "4fbc022d-35e3-46a5-a5a1-48e9a4adfb86"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pile</th>\n",
       "      <th>doc</th>\n",
       "      <th>start_prefix_index</th>\n",
       "      <th>decoded_prefix</th>\n",
       "      <th>prefix_len</th>\n",
       "      <th>gen_len</th>\n",
       "      <th>decoded_phrase</th>\n",
       "      <th>teacher_phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>25079</td>\n",
       "      <td>2050.0</td>\n",
       "      <td>let s:easy_align_delimiters_default = {\\n\\ '':...</td>\n",
       "      <td>464.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>'left_margin': 1, '</td>\n",
       "      <td>'left_margin': 1, '</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>28171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Most current bonding systems use chelating or ...</td>\n",
       "      <td>339.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>support the mineral-depleted collagen in the ...</td>\n",
       "      <td>prevent the collagen from collapsing.\\nThe ef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>22327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Note: This is a GrinGold miner guide, for Bmin...</td>\n",
       "      <td>675.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Check out the list of pools available along wi...</td>\n",
       "      <td>\\n\\nPool 1: https://grin-pool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>25577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Korean Women's Associations United\\n\\n</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Korean Women's Associations United (KWAU</td>\n",
       "      <td>\\n\\nKorean Women's Associations United (K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>29273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>If you have been investing in cryptocurrency f...</td>\n",
       "      <td>182.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>MO is the most mysterious project of all exist...</td>\n",
       "      <td>MO is a project that is not very well known,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  pile    doc  start_prefix_index  \\\n",
       "0         0.0     0  25079              2050.0   \n",
       "1         1.0     0  28171                 0.0   \n",
       "2         2.0     0  22327                 0.0   \n",
       "3         3.0     0  25577                 0.0   \n",
       "4         4.0     0  29273                 0.0   \n",
       "\n",
       "                                      decoded_prefix  prefix_len  gen_len  \\\n",
       "0  let s:easy_align_delimiters_default = {\\n\\ '':...       464.0     11.0   \n",
       "1  Most current bonding systems use chelating or ...       339.0     11.0   \n",
       "2  Note: This is a GrinGold miner guide, for Bmin...       675.0     11.0   \n",
       "3             Korean Women's Associations United\\n\\n         9.0     11.0   \n",
       "4  If you have been investing in cryptocurrency f...       182.0     11.0   \n",
       "\n",
       "                                      decoded_phrase  \\\n",
       "0                                'left_margin': 1, '   \n",
       "1   support the mineral-depleted collagen in the ...   \n",
       "2  Check out the list of pools available along wi...   \n",
       "3           Korean Women's Associations United (KWAU   \n",
       "4  MO is the most mysterious project of all exist...   \n",
       "\n",
       "                                      teacher_phrase  \n",
       "0                                'left_margin': 1, '  \n",
       "1   prevent the collagen from collapsing.\\nThe ef...  \n",
       "2                      \\n\\nPool 1: https://grin-pool  \n",
       "3          \\n\\nKorean Women's Associations United (K  \n",
       "4       MO is a project that is not very well known,  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "q-OmK47oWsmk"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def truncate_strings(df, column_label=\"decoded_prefix\", max_length=2000):\n",
    "    \"\"\"\n",
    "    Truncate string values in a specified column of a DataFrame to keep the last\n",
    "    maximum length characters.\n",
    "    \"\"\"\n",
    "    df[column_label] = df[column_label].astype(str).str.slice(-max_length).str.lower()\n",
    "    return df\n",
    "\n",
    "# Truncate lengths of prefixes (contexts) to avoid upsetting our delicate\n",
    "# (free) CoLab GPU\n",
    "train_data = truncate_strings(train_data, max_length=1300)\n",
    "test_data = truncate_strings(test_data, max_length=1300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "wHYotuvR68Gr",
    "outputId": "76bec51b-ae71-4c24-ff85-4a8db7aae657"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pile</th>\n",
       "      <th>doc</th>\n",
       "      <th>start_prefix_index</th>\n",
       "      <th>decoded_prefix</th>\n",
       "      <th>prefix_len</th>\n",
       "      <th>gen_len</th>\n",
       "      <th>decoded_phrase</th>\n",
       "      <th>teacher_phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>25079</td>\n",
       "      <td>2050.0</td>\n",
       "      <td>let s:easy_align_delimiters_default = {\\n\\ '':...</td>\n",
       "      <td>464.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>'left_margin': 1, '</td>\n",
       "      <td>'left_margin': 1, '</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>28171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>imer and the formation of a hybridized dentin ...</td>\n",
       "      <td>339.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>support the mineral-depleted collagen in the ...</td>\n",
       "      <td>prevent the collagen from collapsing.\\nThe ef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>22327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>g tool - msi afterburner works fine to limit p...</td>\n",
       "      <td>675.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Check out the list of pools available along wi...</td>\n",
       "      <td>\\n\\nPool 1: https://grin-pool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>25577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>korean women's associations united\\n\\n</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Korean Women's Associations United (KWAU</td>\n",
       "      <td>\\n\\nKorean Women's Associations United (K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>29273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>if you have been investing in cryptocurrency f...</td>\n",
       "      <td>182.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>MO is the most mysterious project of all exist...</td>\n",
       "      <td>MO is a project that is not very well known,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  pile    doc  start_prefix_index  \\\n",
       "0         0.0     0  25079              2050.0   \n",
       "1         1.0     0  28171                 0.0   \n",
       "2         2.0     0  22327                 0.0   \n",
       "3         3.0     0  25577                 0.0   \n",
       "4         4.0     0  29273                 0.0   \n",
       "\n",
       "                                      decoded_prefix  prefix_len  gen_len  \\\n",
       "0  let s:easy_align_delimiters_default = {\\n\\ '':...       464.0     11.0   \n",
       "1  imer and the formation of a hybridized dentin ...       339.0     11.0   \n",
       "2  g tool - msi afterburner works fine to limit p...       675.0     11.0   \n",
       "3             korean women's associations united\\n\\n         9.0     11.0   \n",
       "4  if you have been investing in cryptocurrency f...       182.0     11.0   \n",
       "\n",
       "                                      decoded_phrase  \\\n",
       "0                                'left_margin': 1, '   \n",
       "1   support the mineral-depleted collagen in the ...   \n",
       "2  Check out the list of pools available along wi...   \n",
       "3           Korean Women's Associations United (KWAU   \n",
       "4  MO is the most mysterious project of all exist...   \n",
       "\n",
       "                                      teacher_phrase  \n",
       "0                                'left_margin': 1, '  \n",
       "1   prevent the collagen from collapsing.\\nThe ef...  \n",
       "2                      \\n\\nPool 1: https://grin-pool  \n",
       "3          \\n\\nKorean Women's Associations United (K  \n",
       "4       MO is a project that is not very well known,  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YGC4idMirYGg"
   },
   "source": [
    "### Assemble (X,y)'s. [40 points]\n",
    "\n",
    "Your $x$ vectors should be hidden states; $y$'s should be 'future' tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "OdLcQo77ds6A"
   },
   "outputs": [],
   "source": [
    "def assemble_Xy(df, batch_size=2, target_token_offset=3,\n",
    "                model_name=\"gpt2\", remote=False,\n",
    "                print_every=1):\n",
    "\n",
    "  # Yes, this is arguably bad practice, but then we're doing in ML in\n",
    "  # notebooks, so all bets are off\n",
    "  global model\n",
    "  model = LanguageModel('gpt2', device_map='cuda')\n",
    "\n",
    "  X, y = [], []\n",
    "  for i in range(0, len(df), batch_size):\n",
    "    if i % print_every == 100:\n",
    "      print(f\"Processing batch {i}\")\n",
    "\n",
    "    # Get the next batch of data\n",
    "    batch = df.iloc[i:i+batch_size]\n",
    "    # x vectors are the hidden states \n",
    "    # y should be 'future' tokens \n",
    "    with model.trace(batch) as tracer: \n",
    "      hidden_states = tracer.h[-1].detach().cpu()\n",
    "      # Target & Future tokens\n",
    "      target_token = tracer.input_ids[:, -target_token_offset]\n",
    "      future_tokens = tracer.input_ids[:, -target_token_offset+1:]\n",
    "\n",
    "      # Append the hidden states to the X list\n",
    "    X.append(hidden_states)\n",
    "    y.append(future_tokens)\n",
    "\n",
    "    # Cat lists \n",
    "  X = torch.cat(X) \n",
    "  y = torch.cat(y)\n",
    "\n",
    "  return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "_vYaw8VNLf42"
   },
   "outputs": [],
   "source": [
    "def filter_for_eos_outputs(X, y):\n",
    "    refined_pairs = [\n",
    "        (X[idx], each.long()) for idx, each in enumerate(y)\n",
    "        if hasattr(each, 'long')  # Check if each has `.long()` method\n",
    "    ]\n",
    "\n",
    "    # Separate and concatenate the refined X and y\n",
    "    refined_X = torch.cat([pair[0] for pair in refined_pairs])\n",
    "    refined_y = torch.cat([pair[1] for pair in refined_pairs])\n",
    "\n",
    "    return refined_X, refined_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHrIgwlqrs4M"
   },
   "source": [
    "Note: You only need to get this working for gpt2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "fJA6QOhqlAeS",
    "outputId": "a1e814a8-37a2-4ad2-f4c4-1636e5f9377c",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'node'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#X, y = assemble_Xy(train_data.sample(n=16),  batch_size=16,\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#                  model_name=\"meta-llama/Meta-Llama-3-8B\", remote=True)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43massemble_Xy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m X, y \u001b[38;5;241m=\u001b[39m filter_for_eos_outputs(X, y)\n",
      "Cell \u001b[1;32mIn[54], line 8\u001b[0m, in \u001b[0;36massemble_Xy\u001b[1;34m(df, batch_size, target_token_offset, model_name, remote, print_every)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massemble_Xy\u001b[39m(df, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, target_token_offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m      2\u001b[0m                 model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m\"\u001b[39m, remote\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m      3\u001b[0m                 print_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m   \u001b[38;5;66;03m# Yes, this is arguably bad practice, but then we're doing in ML in\u001b[39;00m\n\u001b[0;32m      6\u001b[0m   \u001b[38;5;66;03m# notebooks, so all bets are off\u001b[39;00m\n\u001b[0;32m      7\u001b[0m   \u001b[38;5;28;01mglobal\u001b[39;00m model\n\u001b[1;32m----> 8\u001b[0m   model \u001b[38;5;241m=\u001b[39m \u001b[43mLanguageModel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgpt2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m   X, y \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m     11\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df), batch_size):\n",
      "File \u001b[1;32mc:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nnsight\\models\\LanguageModel.py:160\u001b[0m, in \u001b[0;36mLanguageModel.__init__\u001b[1;34m(self, model_key, tokenizer, automodel, *args, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model_key, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(model_key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator\u001b[39m\u001b[38;5;124m\"\u001b[39m, WrapperModule())\n\u001b[1;32m--> 160\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nnsight\\models\\NNsightModel.py:113\u001b[0m, in \u001b[0;36mNNsight.__init__\u001b[1;34m(self, model_key, dispatch, meta_buffers, *args, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_custom_model:\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;66;03m# Load skeleton of model by putting all tensors on meta.\u001b[39;00m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m init_empty_weights(include_buffers\u001b[38;5;241m=\u001b[39mmeta_buffers):\n\u001b[1;32m--> 113\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_envoy \u001b[38;5;241m=\u001b[39m Envoy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model)\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dispatch \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatched:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# Dispatch ._model on initialization vs lazy dispatching.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nnsight\\models\\LanguageModel.py:198\u001b[0m, in \u001b[0;36mLanguageModel._load\u001b[1;34m(self, repo_id, tokenizer_kwargs, patch_llama_scan, **kwargs)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    191\u001b[0m     patch_llama_scan\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, LlamaConfig)\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config\u001b[38;5;241m.\u001b[39mrope_scaling, \u001b[38;5;28mdict\u001b[39m)\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrope_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mrope_scaling\n\u001b[0;32m    195\u001b[0m ):\n\u001b[0;32m    196\u001b[0m     config\u001b[38;5;241m.\u001b[39mrope_scaling[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrope_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 198\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28msetattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator\u001b[39m\u001b[38;5;124m\"\u001b[39m, WrapperModule())\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:440\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_config\u001b[1;34m(cls, config, **kwargs)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    439\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    443\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    445\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\modeling_utils.py:1544\u001b[0m, in \u001b[0;36mPreTrainedModel._from_config\u001b[1;34m(cls, config, **kwargs)\u001b[0m\n\u001b[0;32m   1541\u001b[0m         model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1544\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;66;03m# restore default dtype if it was modified\u001b[39;00m\n\u001b[0;32m   1547\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1193\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config):\n\u001b[0;32m   1192\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(config)\n\u001b[1;32m-> 1193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer \u001b[38;5;241m=\u001b[39m \u001b[43mGPT2Model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1194\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(config\u001b[38;5;241m.\u001b[39mn_embd, config\u001b[38;5;241m.\u001b[39mvocab_size, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1196\u001b[0m     \u001b[38;5;66;03m# Model parallel\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:900\u001b[0m, in \u001b[0;36mGPT2Model.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    896\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(config)\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mhidden_size\n\u001b[1;32m--> 900\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwte \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwpe \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mEmbedding(config\u001b[38;5;241m.\u001b[39mmax_position_embeddings, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim)\n\u001b[0;32m    903\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(config\u001b[38;5;241m.\u001b[39membd_pdrop)\n",
      "File \u001b[1;32mc:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:170\u001b[0m, in \u001b[0;36mEmbedding.__init__\u001b[1;34m(self, num_embeddings, embedding_dim, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse, _weight, _freeze, device, dtype)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m Parameter(\n\u001b[0;32m    167\u001b[0m         torch\u001b[38;5;241m.\u001b[39mempty((num_embeddings, embedding_dim), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs),\n\u001b[0;32m    168\u001b[0m         requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m _freeze,\n\u001b[0;32m    169\u001b[0m     )\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_weight\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m [\n\u001b[0;32m    173\u001b[0m         num_embeddings,\n\u001b[0;32m    174\u001b[0m         embedding_dim,\n\u001b[0;32m    175\u001b[0m     ], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of weight does not match num_embeddings and embedding_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:181\u001b[0m, in \u001b[0;36mEmbedding.reset_parameters\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset_parameters\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 181\u001b[0m     \u001b[43minit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormal_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fill_padding_idx_with_zero()\n",
      "File \u001b[1;32mc:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\init.py:190\u001b[0m, in \u001b[0;36mnormal_\u001b[1;34m(tensor, mean, std, generator)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Fill the input Tensor with values drawn from the normal distribution.\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \n\u001b[0;32m    177\u001b[0m \u001b[38;5;124;03m:math:`\\mathcal{N}(\\text{mean}, \\text{std}^2)`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;124;03m    >>> nn.init.normal_(w)\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39moverrides\u001b[38;5;241m.\u001b[39mhas_torch_function_variadic(tensor):\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormal_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _no_grad_normal_(tensor, mean, std, generator)\n",
      "File \u001b[1;32mc:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\overrides.py:1717\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[1;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_torch_function_mode_enabled():\n\u001b[0;32m   1714\u001b[0m     \u001b[38;5;66;03m# if we're here, the mode must be set to a TorchFunctionStackMode\u001b[39;00m\n\u001b[0;32m   1715\u001b[0m     \u001b[38;5;66;03m# this unsets it and calls directly into TorchFunctionStackMode's torch function\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _pop_mode_temporarily() \u001b[38;5;28;01mas\u001b[39;00m mode:\n\u001b[1;32m-> 1717\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mmode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1718\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m   1719\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_device.py:106\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[1;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    105\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m--> 106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\init.py:190\u001b[0m, in \u001b[0;36mnormal_\u001b[1;34m(tensor, mean, std, generator)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Fill the input Tensor with values drawn from the normal distribution.\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \n\u001b[0;32m    177\u001b[0m \u001b[38;5;124;03m:math:`\\mathcal{N}(\\text{mean}, \\text{std}^2)`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;124;03m    >>> nn.init.normal_(w)\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39moverrides\u001b[38;5;241m.\u001b[39mhas_torch_function_variadic(tensor):\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormal_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _no_grad_normal_(tensor, mean, std, generator)\n",
      "File \u001b[1;32mc:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\overrides.py:1717\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[1;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_torch_function_mode_enabled():\n\u001b[0;32m   1714\u001b[0m     \u001b[38;5;66;03m# if we're here, the mode must be set to a TorchFunctionStackMode\u001b[39;00m\n\u001b[0;32m   1715\u001b[0m     \u001b[38;5;66;03m# this unsets it and calls directly into TorchFunctionStackMode's torch function\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _pop_mode_temporarily() \u001b[38;5;28;01mas\u001b[39;00m mode:\n\u001b[1;32m-> 1717\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mmode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1718\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m   1719\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nnsight\\contexts\\GraphBasedContext.py:331\u001b[0m, in \u001b[0;36mGlobalTracingContext.GlobalTracingTorchHandler.__torch_function__\u001b[1;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_VariableFunctionsClass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m:\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m GlobalTracingContext\u001b[38;5;241m.\u001b[39mGLOBAL_TRACING_CONTEXT\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m    328\u001b[0m         func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    329\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\init.py:190\u001b[0m, in \u001b[0;36mnormal_\u001b[1;34m(tensor, mean, std, generator)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Fill the input Tensor with values drawn from the normal distribution.\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \n\u001b[0;32m    177\u001b[0m \u001b[38;5;124;03m:math:`\\mathcal{N}(\\text{mean}, \\text{std}^2)`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;124;03m    >>> nn.init.normal_(w)\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39moverrides\u001b[38;5;241m.\u001b[39mhas_torch_function_variadic(tensor):\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormal_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _no_grad_normal_(tensor, mean, std, generator)\n",
      "File \u001b[1;32mc:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\overrides.py:1739\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[1;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1731\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1732\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDefining your `__torch_function__ as a plain method is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1733\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be an error in future, please define it as a classmethod.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1734\u001b[0m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[0;32m   1735\u001b[0m     )\n\u001b[0;32m   1737\u001b[0m \u001b[38;5;66;03m# Use `public_api` instead of `implementation` so __torch_function__\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;66;03m# implementations can do equality/identity comparisons.\u001b[39;00m\n\u001b[1;32m-> 1739\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_func_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m   1742\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nnsight\\tracing\\Proxy.py:279\u001b[0m, in \u001b[0;36mProxy.__torch_function__\u001b[1;34m(cls, orig_method, types, args, kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m     proxy \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m    277\u001b[0m util\u001b[38;5;241m.\u001b[39mapply(args, get_proxy, Proxy)\n\u001b[1;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mproxy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m    280\u001b[0m     target\u001b[38;5;241m=\u001b[39morig_method,\n\u001b[0;32m    281\u001b[0m     args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m    282\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m    283\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'node'"
     ]
    }
   ],
   "source": [
    "#X, y = assemble_Xy(train_data.sample(n=16),  batch_size=16,\n",
    "#                  model_name=\"meta-llama/Meta-Llama-3-8B\", remote=True)\n",
    "X, y = assemble_Xy(train_data,  batch_size=1,\n",
    "                   model_name=\"gpt2\", remote=False)\n",
    "X, y = filter_for_eos_outputs(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S3FmjzwaPxLZ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UCtjIUCBpwjj"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "xJNUaTdZtGIh",
    "outputId": "7d0d0800-3b4a-4548-e357-a49e0518b43e",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_X, test_y = assemble_Xy(test_data,  batch_size=1,\n",
    "                   model_name=\"openai-community/gpt2\", remote=False)\n",
    "test_X, test_y = filter_for_eos_outputs(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F3STh_bsakax",
    "outputId": "eeb60e77-4a22-4de0-f3de-c157d07d3c14"
   },
   "outputs": [],
   "source": [
    "test_y.shape, test_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfrVB5TNr1n-"
   },
   "source": [
    "Below we have included some code to shrink the vocab size in the interest of efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TJjd4yN068Gt"
   },
   "outputs": [],
   "source": [
    "def make_reduced_vocab_space(y, test_y):\n",
    "    all_target_tokens = torch.cat([test_y, y], dim = 0)\n",
    "    unique_tokens = torch.unique(all_target_tokens[:, 0])\n",
    "    reduced_vocab_size = len(unique_tokens)\n",
    "    token_to_reduced = {token.item(): i for i, token in enumerate(unique_tokens)}\n",
    "    return reduced_vocab_size, token_to_reduced\n",
    "\n",
    "def map_target_to_space(y, token_map):\n",
    "    y_reduced = [torch.tensor([token_map[t.item()]]) for t in y]\n",
    "    y_reduced = torch.stack(y_reduced, dim = 0)\n",
    "    return y_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dmC4ck7r68Gt"
   },
   "outputs": [],
   "source": [
    "# Make the task a bit more manageable\n",
    "reduced_vocab_size, token_map = make_reduced_vocab_space(y, test_y)\n",
    "y = map_target_to_space(y, token_map)\n",
    "test_y = map_target_to_space(test_y, token_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zTcS14_hhDGS"
   },
   "source": [
    "### 2. Train a linear probe [40 points]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4lFh8yh2UljR",
    "outputId": "6de5fac7-e666-4f25-ca3f-33921777e8c1"
   },
   "outputs": [],
   "source": [
    "print(f'Reduced space from {model.tokenizer.vocab_size} --> {reduced_vocab_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "taS9IH_ZSfZ5"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create a linear model with output dimension equal to number of tokens in our vocab\n",
    "input_dims = X.shape[1]\n",
    "# output_dims = model.tokenizer.vocab_size\n",
    "output_dims = reduced_vocab_size\n",
    "\n",
    "# TODO define the model\n",
    "probe_model = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qYqhmbwXVEWm"
   },
   "outputs": [],
   "source": [
    "# TODO fit the model; print out losses per Epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ulsgwy62hH16"
   },
   "source": [
    "### 3. Evaluate results [20 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wp5Eg3Yjse-K"
   },
   "source": [
    "Below you should make predictions on the test set and then evaluate your accuracy. To contextualize this, you should compare to what you would get with random chance (just guessing future tokens). Print out the accuracy you get with your probe model and the accuracy you'd get by chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EHczy2RHsu9V"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
